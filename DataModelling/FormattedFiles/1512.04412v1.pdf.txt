In this paper, we present Multitask Network Cascades for instance-aware semantic segmentation.
Our model consists of three networks, respectively differentiating instances, estimating masks, and categorizing objects.
We develop an algorithm for the nontrivial end-to-end training of this causal, cascaded structure.
Our solution is a clean, single-step training framework and can be generalized to cascades that have more stages.
We demonstrate state-of-the-art instance-aware semantic segmentation accuracy on PASCAL VOC.
Meanwhile, our method takes only 360ms testing an image using VGG-16, which is two orders of magnitude faster than previous systems for this challenging problem.
As a by product, our method also achieves compelling object detection results which surpass the competitive Fast/Faster R-CNN systems.
The method described in this paper is the foundation of our submissions to the MS COCO 2015 segmentation competition, where we won the 1st place.
 In this work, we address instance-aware semantic segmentation solely based on CNNs, without using external modules (e.g., [1]).
We observe that the instance-aware semantic segmentation task can be decomposed into three different and related sub-tasks.
We expect that each sub-task is simpler than the original instance segmentation task, and is more easily addressed by convolutional networks.
Driven by this decomposition, we propose Multi-task Network Cascades (MNCs) for accurate and fast instanceaware semantic segmentation.
Our network cascades have three stages, each of which addresses one sub-task.
But unlike many multi-task learning applications, in our method a later stage depends on the outputs of an earlier stage, forming a causal cascade (see Fig.
So we call our structures “multi-task cascades”.
For example, our mask estimating layer takes convolutional features and predicted box instances as inputs, both of which are outputs of other layers.
To achieve theoretically valid backpropagation, we develop a layer that is differentiable with respect to the spatial coordinates, so the gradient terms can be computed.
Our cascade model can thus be trained end-to-end via a clean, single-step framework.
Meanwhile, under this training framework, our cascade model can be extended to more stages, leading to improvements on accuracy.
We comprehensively evaluate our method on the PASCAL VOC dataset.
Our method results in 63.5% mean Average Precision (mAPr), about 3.0% higher than the previous best results [14, 7] using the same VGG network [27].
We demonstrate excellent accuracy on the challenging MS COCO segmentation dataset using an extremely deep 101-layer residual net (ResNet-101) [16], and also report our 1st-place result in the COCO segmentation track in ILSVRC & COCO 2015 competitions.
We train the entire network cascade end-to-end with a uniﬁed loss function.
2 illustrates our cascade model.
In our MNC model, the network takes an image of arbitrary size as the input, and outputs instance-aware semantic segmentation results.
In this section we describe the deﬁnition for each stage.
In the next section we introduce an end-to-end training algorithm to address the causal dependency.
The network structure and loss function of this stage follow the work of Region Proposal Networks (RPNs) [26], which we brieﬂy describe as follows for completeness.
We use the RPN loss function given in [26].
This loss function serves as the loss term L1 of our stage 1.
Given a box predicted by stage 1, we extract a feature of this box by Region-of-Interest (RoI) pooling [15, 9].
We append two extra fully-connected (fc) layers to this feature for each box.
DeepMask applies the regression layers to dense sliding windows (fully-convolutionally), but our method only regresses masks from a few proposed boxes and so reduces computational cost.
Moreover, mask regression is only one stage in our network cascade that shares features among multiple stages, so the marginal cost of the mask regression layers is very small.
Given a box predicted by stage 1, we also extract a feature by RoI pooling.
Following [13], we also use another box-based pathway, where the RoI pooled features directly fed into two 4096-d fc layers (this pathway is not illustrated in Fig.
We deﬁne the loss function of the entire cascade as: L(Θ) =L1(B(Θ)) + L2(M (Θ) | B(Θ)) + L3(C(Θ) | B(Θ), M (Θ)), where balance weights of 1 are implicitly used among the three terms.
In this section, we develop a differentiable RoI warping layer to account for the gradient w.r.t.
the box position, we perform RoI pooling by a differentiable RoI warping layer followed by standard max pooling.
We use F(Θ) to denote the full-image convolutional feature map.
We note that these operations are performed for each channel independently.
We note that because κ is non-zero in a small interval, the actual computation of Eqn.(7) involves a very few terms.
According to the chain rule, for backpropagation involving Eqn.(6) we need to compute: where we use ∂Bi to denote ∂xi, ∂yi, ∂wi, and ∂hi for in Eqn.(9) can be derived from simplicity.
After the differentiable RoI warping layer, we append a max pooling layer to perform the RoI max pooling behavior.
We expect the RoI warping layer to produce a sufﬁciently ﬁne resolution, which is set as W (cid:48) × H(cid:48) = 28 × 28 in this paper.
Our RoI warping layer is also driven by the differentiable property of interpolating features.
But due to concerns on fast inference, we only present MNCs with up to 5 stages.
For generating the proposals for stage 2, we use non-maximum suppression (NMS) to reduce redundant candidates.
During inference, we use the same NMS strategy to produce 300 proposals for stage 2.
(ii) On stage 2, for each proposed box we ﬁnd its highest overlapping ground truth mask.
(iii) On stage 3, we consider two sets of positive/negative samples.
We use the ImageNet pretrained models (e.g., VGG-16 [27]) to initialize the shared convolutional layers and the corresponding 4096-d fc layers.
We adopt an image-centric training framework [9]: the shared convolutional layers are computed on the entire image, while the RoIs are randomly sampled for computing loss functions.
In our system, each mini-batch involves 1 image, 256 sampled anchors for stage 1 as in [26]2, and 64 2Though we sample 256 anchors on stage 1 for computing the loss  On stage 3, bounding boxes updated by the box regression layer are used as the input to stage 4.
We also compute the gradients involved in L3(C(Θ) | B(Θ), M (Θ)), where the dependency on B(Θ) and M (Θ) is determined by Eqn.(3).
In summary, given the differentiable RoI warping module, we have all the necessary components for backpropagation (other components are either standard, or trivial to implement).
We train the model by stochastic gradient descent (SGD), implemented in the Caffe library [19].
Cascades with More Stages Next we extend the cascade model to more stages within In Fast R-CNN [9], the (N+1)-way classiﬁer is trained jointly with class-wise bounding box regression.
Inspired by this practice, on stage 3, we add a 4(N+1)-d fc layer for regression class-wise bounding boxes [9], which is a sibling layer with the classiﬁer layer.
The inference step with box regression, however, is not as straightforward as in object detection, because our ultimate outputs are masks instead of boxes.
So during inference, we ﬁrst run the entire 3-stage network and obtain the regressed boxes on stage 3.
This inference process can be iterated, but we have observed negligible gains.
3), it is easy to adopt our algorithm in Sec.
Training the model in this way makes the training-time structure consistent with the 1To avoid multiplying the number of proposals by the number of categories, for each box we only use the highest scored category’s bounding box regressor.
We train the model using a learning rate of 0.001 for 32k iterations, and 0.0001 for the next 8k.
We train the model in 8 GPUs, each GPU holding 1 mini-batch (so the effective mini-batch size is ×8).
We do not adopt multi-scale training/testing [15, 9], as it provides no good trade-off on speed vs.
We use 5-stage inference for both 3-stage and 5-stage trained structures.
We post-process this list to reduce similar predictions.
We ﬁrst apply NMS (using box-level IoU 0.3 [10]) on the list of 600 instances based on their category scores.
After that, for each not-suppressed instance, we ﬁnd its “similar” instances which are deﬁned as the suppressed instances that overlap with it by IoU ≥ 0.5.
Experiments on PASCAL VOC 2012 We follow the protocols used in recent papers [13, 7, 14] for evaluating instance-aware semantic segmentation.
We use the segmentation annotations in [12] for training and evaluation, following [13, 7, 14].
We evaluate the mean Average Precision, which is referred to as mean APr [13] or simply mAPr.
We evaluate mAPr using IoU thresholds at 0.5 and 0.7.
We remark that in this table all results are obtained function, the network of stage 1 is still computed fully-convolutionally on the entire image and produces all proposals that are used by later stages.
We show results using ZF net [30] that has 5 convolutional layers and 3 fc layers, and VGG-16 net [27] that has 13 convolutional layers and 3 fc layers.
As a simple baseline (Table 1, a), we train the three stages step-by-step without sharing their features.
We note that this baseline result is competitive (see also Table 2), suggesting that decomposing the task into three sub-tasks is an effective solution.
Next we experiment with the single-step, end-to-end training algorithm developed in Sec.
We note that in Table 1 (a), (b), and (c), the models have the same structure for training.
4, we are able to train the network by backpropagation in a theoretically sound way.
We note that all results in Table 1 are based on the same 5-stage inference strategy.
The series of comparisons are also observed when using the ZF net as the pre-trained model (Table 1, left), showing the generality of our ﬁndings.
The running time of [14] is our estimation based on the description from the paper.
Detailed testing time (seconds) per image of our method using 5-stage inference.
Our baseline segmentation result (%) on the MS COCO test-dev set.
In Table 2 we compare with SDS [13], Hypercolumn [14], and CFM [7], which are existing CNN-based semantic segmentation methods that are able to identify instances.
These papers reported their mAPr under the same protocol used by our experiments.
Our MNC has ∼3% higher mAPr@0.5 than previous best results.
Our method also has higher mAPr@0.7 than previous methods.
Fig 4 shows some examples of our results on the validation set.
Our method can handle challenging cases where multiple instances of the same category are spatially connected to each other (e.g., Fig 4, ﬁrst row).
Our method has an inference-time speed of 360ms per image (Table 2), evaluated on an Nvidia K40 GPU.
Our method does not require any external region proposal method, whereas the region proposal step in SDS, Hypercolumn, and CFM costs 30s using MCG.
Furthermore, our method uses the shared convolutional features for the three sub-tasks and avoids redundant computation.
Our system is about two orders of magnitude faster than previous systems.
We are also interested in the box-level object detection performance (mAPb), so that we can compare with more systems that are designed for object detection.
We train our model on the PASCAL VOC 2012 trainval set, and evaluate on the PASCAL VOC 2012 test set for object detection.
Given mask-level instances generated by our model, we simply assign a tight bounding box to each instance.
Table 4 shows that our result (70.9%) compares favorably to the recent Fast/Faster R-CNN systems [9, 26].
We note that our result is obtained with fewer training images (without the 2007 set), but with mask-level annotations.
This experiment shows the effectiveness of our algorithm for detecting both boxand mask-level instances.
But our method also has box-level outputs from the box regression layers in stage 3/5.
Using these box layers’ outputs (box coordinates and scores) in place of the mask-level outputs, we obtain an mAPb of 73.5% (Table 4).
Finally, we train the MNC model on the union set of 2007 trainval+test and 2012 trainval.
Under this setting, we obtain an mAPb of 75.9% (Table 4), substantially better than Fast/Faster R-CNN [9, 26].
Experiments on MS COCO Segmentation We further evaluate on the MS COCO dataset [22].
Following the COCO guidelines, we use the 80k+40k trainval images to train, and report the results on the test-dev set.
We evaluate the standard COCO metric (mAPr@IoU=[0.5:0.95]) and also the PASCAL metrics (mAPr@IoU=0.5).
Table 5 shows our method using VGG-16 has a result of 19.5%/39.7%.
The end-to-end training behavior and the independence of external models make our method easily enjoy gains from deeper representations.
By replacing VGG-16 with an extremely deep 101-layer network (ResNet-101) [16], we achieve 24.6%/44.3% on the MS COCO test-dev set (Table 5).
On our baseline result, we further adopt global context modeling and multi-scale testing as in [16], and ensembling.
Our ﬁnal result on the test-challenge set is 28.2%/51.5%, which won the 1st place in the COCO segmentation track3 of ILSVRC & COCO 2015 competitions.
We have presented Multi-task Network Cascades for fast and accurate instance segmentation.
We believe that the idea of exploiting network cascades in a multi-task learning framework is general.
Our method is designed with fast inference in mind, and is orthogonal to some other successful strategies developed previously for semantic segmentation.
Weaklyand semi-supervised learning of a dcnn for semantic image segmentation